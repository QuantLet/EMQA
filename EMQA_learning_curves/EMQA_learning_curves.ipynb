{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EMQA_learning_curves/EMQA_learning_curves.ipynb)\n\n# EMQA_learning_curves\n\nLearning curves: good fit vs overfitting (simulated data).\n\n**Output:** `ml_learning_curves.pdf`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams.update({\n    'figure.facecolor': 'none',\n    'axes.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.transparent': True,\n    'axes.grid': False,\n    'axes.spines.top': False,\n    'axes.spines.right': False,\n    'font.size': 11,\n    'figure.figsize': (12, 6),\n})\n\nCOLORS = {\n    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n    'cyan': '#00BCD4', 'amber': '#B5853F'\n}\n\ndef save_fig(fig, name):\n    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n    print(f\"Saved: {name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "np.random.seed(42)\n\nepochs = np.arange(1, 101)\n\n# --- (A) Good fit ---\ntrain_good = 1.0 * np.exp(-0.04 * epochs) + 0.15 + np.random.normal(0, 0.008, len(epochs))\nval_good = 1.1 * np.exp(-0.035 * epochs) + 0.20 + np.random.normal(0, 0.012, len(epochs))\n\n# Early stopping point\nes_epoch = 65\n\n# --- (B) Overfitting ---\ntrain_overfit = 1.0 * np.exp(-0.05 * epochs) + 0.05 + np.random.normal(0, 0.006, len(epochs))\n# Validation first decreases then increases\nval_overfit_base = 1.1 * np.exp(-0.04 * epochs) + 0.20\nval_overfit_rise = np.where(epochs > 30, 0.005 * (epochs - 30)**1.1, 0)\nval_overfit = val_overfit_base + val_overfit_rise + np.random.normal(0, 0.01, len(epochs))\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# (A) Good fit\nax = axes[0]\nax.plot(epochs, train_good, color=COLORS['green'], lw=2, label='Train Loss')\nax.plot(epochs, val_good, color=COLORS['orange'], lw=2, label='Validation Loss')\nax.axvline(es_epoch, color=COLORS['red'], ls='--', lw=1.5, label=f'Early Stopping (epoch {es_epoch})')\nax.set_title('(A) Good Fit', fontsize=13, fontweight='bold')\nax.set_xlabel('Epoch')\nax.set_ylabel('Loss')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10), frameon=False, ncol=3)\n\n# (B) Overfitting\nax2 = axes[1]\nax2.plot(epochs, train_overfit, color=COLORS['green'], lw=2, label='Train Loss')\nax2.plot(epochs, val_overfit, color=COLORS['orange'], lw=2, label='Validation Loss')\n\n# Highlight overfit gap\noverfit_start = 30\nmask = epochs >= overfit_start\nax2.fill_between(epochs[mask], train_overfit[mask], val_overfit[mask],\n                 color=COLORS['red'], alpha=0.2, label='Overfit Gap')\nax2.axvline(overfit_start, color=COLORS['gray'], ls=':', lw=1, label='Divergence Point')\nax2.set_title('(B) Overfitting', fontsize=13, fontweight='bold')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Loss')\nax2.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10), frameon=False, ncol=4)\n\nfig.suptitle('Learning Curves: Good Fit vs Overfitting', fontsize=15, fontweight='bold', y=1.02)\nfig.tight_layout()\nsave_fig(fig, 'ml_learning_curves.pdf')\nplt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}