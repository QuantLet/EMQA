{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EMQA_ml_monitor/EMQA_ml_monitor.ipynb)\n",
    "\n",
    "# EMQA_ml_monitor\n",
    "\n",
    "Model monitoring and drift detection for ML forecasting in electricity markets.\n",
    "Demonstrates techniques to detect when a deployed model needs retraining.\n",
    "\n",
    "**Key Concepts:**\n",
    "1. **Performance Monitoring**: Track error metrics over time\n",
    "2. **Data Drift**: Detect changes in input feature distributions\n",
    "3. **Concept Drift**: Detect changes in the target-feature relationship\n",
    "4. **Recalibration Triggers**: When to retrain the model\n",
    "\n",
    "**Output:** `ml_monitor.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Professional plot styling\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'none',\n",
    "    'axes.facecolor': 'none',\n",
    "    'savefig.facecolor': 'none',\n",
    "    'savefig.transparent': True,\n",
    "    'axes.grid': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'font.size': 11,\n",
    "    'figure.figsize': (12, 6),\n",
    "})\n",
    "\n",
    "COLORS = {\n",
    "    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n",
    "    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n",
    "    'cyan': '#00BCD4', 'amber': '#B5853F'\n",
    "}\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n",
    "    print(f\"Saved: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and train a model for monitoring demonstration\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/QuantLet/EMQA/main/EMQA_actual_vs_predicted/ro_de_prices_full.csv'\n",
    "df = pd.read_csv(url, parse_dates=['date'], index_col='date')\n",
    "print(f'Loaded {len(df)} observations')\n",
    "\n",
    "# Feature engineering\n",
    "data = df[['ro_price']].copy()\n",
    "data['target'] = data['ro_price'].shift(-1)\n",
    "\n",
    "for lag in [1, 2, 3, 7, 14]:\n",
    "    data[f'ro_lag_{lag}'] = data['ro_price'].shift(lag)\n",
    "\n",
    "for w in [7, 14, 30]:\n",
    "    data[f'ro_ma_{w}'] = data['ro_price'].shift(1).rolling(w).mean()\n",
    "    data[f'ro_std_{w}'] = data['ro_price'].shift(1).rolling(w).std()\n",
    "\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "\n",
    "if 'de_price' in df.columns:\n",
    "    data['de_lag_1'] = df['de_price'].shift(1)\n",
    "\n",
    "data = data.dropna()\n",
    "feature_cols = [c for c in data.columns if c not in ['target', 'ro_price']]\n",
    "print(f\"Features: {len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Performance Monitoring\n",
    "\n",
    "Track model performance over rolling windows to detect degradation.\n",
    "A model trained on historical data may lose predictive power as market conditions change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train initial model on first 50% of data\n",
    "train_end = int(len(data) * 0.5)\n",
    "X_train = data[feature_cols].iloc[:train_end]\n",
    "y_train = data['target'].iloc[:train_end]\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, max_depth=8, random_state=42, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions for the monitoring period (remaining 50%)\n",
    "monitor_data = data.iloc[train_end:]\n",
    "X_monitor = monitor_data[feature_cols]\n",
    "y_monitor = monitor_data['target']\n",
    "\n",
    "predictions = model.predict(X_monitor)\n",
    "errors = y_monitor.values - predictions\n",
    "\n",
    "print(f\"Training period: {data.index[0].date()} to {data.index[train_end-1].date()}\")\n",
    "print(f\"Monitoring period: {monitor_data.index[0].date()} to {monitor_data.index[-1].date()}\")\n",
    "print(f\"Monitoring observations: {len(monitor_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate rolling performance metrics (30-day windows)\n",
    "window = 30\n",
    "\n",
    "rolling_mae = pd.Series(np.abs(errors), index=monitor_data.index).rolling(window).mean()\n",
    "rolling_rmse = pd.Series(errors**2, index=monitor_data.index).rolling(window).mean().apply(np.sqrt)\n",
    "rolling_bias = pd.Series(errors, index=monitor_data.index).rolling(window).mean()  # Mean error (bias)\n",
    "\n",
    "# Baseline: performance on training set\n",
    "train_pred = model.predict(X_train)\n",
    "baseline_mae = mean_absolute_error(y_train, train_pred)\n",
    "baseline_rmse = np.sqrt(mean_squared_error(y_train, train_pred))\n",
    "\n",
    "print(f\"Baseline MAE (training): {baseline_mae:.2f} EUR/MWh\")\n",
    "print(f\"Baseline RMSE (training): {baseline_rmse:.2f} EUR/MWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize performance monitoring\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Panel 1: Rolling MAE with baseline threshold\n",
    "ax1 = axes[0]\n",
    "ax1.plot(rolling_mae.index, rolling_mae.values, color=COLORS['blue'], lw=1.5, label='Rolling MAE (30d)')\n",
    "ax1.axhline(baseline_mae, color=COLORS['green'], ls='--', lw=1.5, label=f'Baseline MAE = {baseline_mae:.1f}')\n",
    "ax1.axhline(baseline_mae * 1.5, color=COLORS['red'], ls='--', lw=1.5, label='Alert Threshold (1.5x)')\n",
    "\n",
    "# Highlight periods exceeding threshold\n",
    "alert_mask = rolling_mae > baseline_mae * 1.5\n",
    "ax1.fill_between(rolling_mae.index, 0, rolling_mae.values, \n",
    "                 where=alert_mask, color=COLORS['red'], alpha=0.2)\n",
    "\n",
    "ax1.set_ylabel('MAE (EUR/MWh)')\n",
    "ax1.set_title('Performance Monitoring: Rolling MAE', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Panel 2: Rolling RMSE\n",
    "ax2 = axes[1]\n",
    "ax2.plot(rolling_rmse.index, rolling_rmse.values, color=COLORS['purple'], lw=1.5, label='Rolling RMSE (30d)')\n",
    "ax2.axhline(baseline_rmse, color=COLORS['green'], ls='--', lw=1.5, label=f'Baseline RMSE = {baseline_rmse:.1f}')\n",
    "ax2.set_ylabel('RMSE (EUR/MWh)')\n",
    "ax2.set_title('Performance Monitoring: Rolling RMSE', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Panel 3: Rolling bias (systematic under/over prediction)\n",
    "ax3 = axes[2]\n",
    "ax3.fill_between(rolling_bias.index, 0, rolling_bias.values, \n",
    "                 where=rolling_bias >= 0, color=COLORS['green'], alpha=0.5, label='Over-prediction')\n",
    "ax3.fill_between(rolling_bias.index, 0, rolling_bias.values, \n",
    "                 where=rolling_bias < 0, color=COLORS['red'], alpha=0.5, label='Under-prediction')\n",
    "ax3.axhline(0, color=COLORS['gray'], ls='-', lw=1)\n",
    "\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Bias (EUR/MWh)')\n",
    "ax3.set_title('Performance Monitoring: Rolling Bias (Mean Error)', fontsize=13, fontweight='bold')\n",
    "ax3.legend(loc='upper right', frameon=False)\n",
    "\n",
    "fig.suptitle('Model Performance Monitoring Dashboard', fontsize=15, fontweight='bold', y=1.01)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Drift Detection\n",
    "\n",
    "Data drift occurs when the distribution of input features changes over time.\n",
    "We use statistical tests to detect significant distribution shifts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_psi(reference, current, bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Population Stability Index (PSI) for drift detection.\n",
    "    PSI < 0.1: No significant drift\n",
    "    PSI 0.1-0.2: Moderate drift (monitor)\n",
    "    PSI > 0.2: Significant drift (action required)\n",
    "    \"\"\"\n",
    "    # Create bins based on reference distribution\n",
    "    breakpoints = np.percentile(reference, np.linspace(0, 100, bins + 1))\n",
    "    breakpoints = np.unique(breakpoints)  # Remove duplicates\n",
    "    \n",
    "    # Calculate proportions in each bin\n",
    "    ref_counts = np.histogram(reference, bins=breakpoints)[0] + 1  # Add 1 to avoid division by zero\n",
    "    cur_counts = np.histogram(current, bins=breakpoints)[0] + 1\n",
    "    \n",
    "    ref_pct = ref_counts / ref_counts.sum()\n",
    "    cur_pct = cur_counts / cur_counts.sum()\n",
    "    \n",
    "    # PSI formula\n",
    "    psi = np.sum((cur_pct - ref_pct) * np.log(cur_pct / ref_pct))\n",
    "    return psi\n",
    "\n",
    "def ks_test_drift(reference, current):\n",
    "    \"\"\"\n",
    "    Kolmogorov-Smirnov test for distribution comparison.\n",
    "    Returns: (KS statistic, p-value)\n",
    "    \"\"\"\n",
    "    return stats.ks_2samp(reference, current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature distributions: training vs monitoring period\n",
    "# Split monitoring into quarters for temporal analysis\n",
    "quarter_size = len(monitor_data) // 4\n",
    "quarters = [\n",
    "    ('Q1', monitor_data.iloc[:quarter_size]),\n",
    "    ('Q2', monitor_data.iloc[quarter_size:2*quarter_size]),\n",
    "    ('Q3', monitor_data.iloc[2*quarter_size:3*quarter_size]),\n",
    "    ('Q4', monitor_data.iloc[3*quarter_size:])\n",
    "]\n",
    "\n",
    "# Calculate drift metrics for key features\n",
    "key_features = ['ro_lag_1', 'ro_ma_7', 'ro_std_7', 'day_of_week']\n",
    "\n",
    "drift_results = []\n",
    "for feat in key_features:\n",
    "    ref_data = X_train[feat].values\n",
    "    for q_name, q_data in quarters:\n",
    "        cur_data = q_data[feat].values\n",
    "        psi = calculate_psi(ref_data, cur_data)\n",
    "        ks_stat, ks_pval = ks_test_drift(ref_data, cur_data)\n",
    "        drift_results.append({\n",
    "            'Feature': feat,\n",
    "            'Period': q_name,\n",
    "            'PSI': psi,\n",
    "            'KS_Stat': ks_stat,\n",
    "            'KS_pval': ks_pval,\n",
    "            'Drift': 'Yes' if psi > 0.2 or ks_pval < 0.01 else ('Monitor' if psi > 0.1 else 'No')\n",
    "        })\n",
    "\n",
    "drift_df = pd.DataFrame(drift_results)\n",
    "print(\"Data Drift Analysis:\")\n",
    "print(drift_df.pivot(index='Feature', columns='Period', values='Drift'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data drift using PSI heatmap\n",
    "psi_pivot = drift_df.pivot(index='Feature', columns='Period', values='PSI')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Panel 1: PSI Heatmap\n",
    "ax1 = axes[0]\n",
    "im = ax1.imshow(psi_pivot.values, cmap='RdYlGn_r', aspect='auto', vmin=0, vmax=0.3)\n",
    "\n",
    "ax1.set_xticks(range(len(psi_pivot.columns)))\n",
    "ax1.set_xticklabels(psi_pivot.columns)\n",
    "ax1.set_yticks(range(len(psi_pivot.index)))\n",
    "ax1.set_yticklabels(psi_pivot.index)\n",
    "\n",
    "# Add value annotations\n",
    "for i in range(len(psi_pivot.index)):\n",
    "    for j in range(len(psi_pivot.columns)):\n",
    "        val = psi_pivot.values[i, j]\n",
    "        color = 'white' if val > 0.15 else 'black'\n",
    "        ax1.text(j, i, f'{val:.2f}', ha='center', va='center', color=color, fontsize=10)\n",
    "\n",
    "ax1.set_title('Population Stability Index (PSI) by Feature', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Colorbar\n",
    "cbar = plt.colorbar(im, ax=ax1, shrink=0.8)\n",
    "cbar.set_label('PSI')\n",
    "\n",
    "# Panel 2: Distribution comparison for one feature\n",
    "ax2 = axes[1]\n",
    "feat_to_show = 'ro_lag_1'\n",
    "\n",
    "ax2.hist(X_train[feat_to_show], bins=30, alpha=0.6, color=COLORS['blue'], \n",
    "         density=True, label='Training', edgecolor='white')\n",
    "ax2.hist(X_monitor[feat_to_show], bins=30, alpha=0.6, color=COLORS['red'],\n",
    "         density=True, label='Monitoring', edgecolor='white')\n",
    "\n",
    "ax2.set_xlabel(f'{feat_to_show} (EUR/MWh)')\n",
    "ax2.set_ylabel('Density')\n",
    "ax2.set_title(f'Distribution Shift: {feat_to_show}', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Add KS test result\n",
    "ks_stat, ks_pval = ks_test_drift(X_train[feat_to_show].values, X_monitor[feat_to_show].values)\n",
    "ax2.text(0.05, 0.95, f'KS stat: {ks_stat:.3f}\\np-value: {ks_pval:.4f}', \n",
    "         transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "fig.suptitle('Data Drift Detection', fontsize=15, fontweight='bold', y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concept Drift Detection\n",
    "\n",
    "Concept drift occurs when the relationship between features and target changes.\n",
    "We detect this by monitoring:\n",
    "- Prediction residuals distribution\n",
    "- Feature importance stability\n",
    "- CUSUM control charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cusum_control(errors, threshold=5.0, drift_k=0.5):\n",
    "    \"\"\"\n",
    "    CUSUM (Cumulative Sum) control chart for drift detection.\n",
    "    Detects systematic shifts in error distribution.\n",
    "    \n",
    "    Returns:\n",
    "        cusum_pos: Upper CUSUM (detects positive shift)\n",
    "        cusum_neg: Lower CUSUM (detects negative shift)\n",
    "        alerts: Boolean array of drift alerts\n",
    "    \"\"\"\n",
    "    n = len(errors)\n",
    "    errors_standardized = (errors - np.mean(errors[:100])) / np.std(errors[:100])  # Standardize using initial period\n",
    "    \n",
    "    cusum_pos = np.zeros(n)\n",
    "    cusum_neg = np.zeros(n)\n",
    "    \n",
    "    for i in range(1, n):\n",
    "        cusum_pos[i] = max(0, cusum_pos[i-1] + errors_standardized[i] - drift_k)\n",
    "        cusum_neg[i] = max(0, cusum_neg[i-1] - errors_standardized[i] - drift_k)\n",
    "    \n",
    "    alerts = (cusum_pos > threshold) | (cusum_neg > threshold)\n",
    "    return cusum_pos, cusum_neg, alerts\n",
    "\n",
    "# Calculate CUSUM for prediction errors\n",
    "cusum_pos, cusum_neg, drift_alerts = cusum_control(errors, threshold=4.0)\n",
    "\n",
    "print(f\"Drift alerts detected: {drift_alerts.sum()} out of {len(drift_alerts)} observations\")\n",
    "if drift_alerts.any():\n",
    "    first_alert = monitor_data.index[np.argmax(drift_alerts)]\n",
    "    print(f\"First drift alert: {first_alert.date()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize CUSUM control chart\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8), sharex=True)\n",
    "\n",
    "# Panel 1: Prediction errors\n",
    "ax1 = axes[0]\n",
    "ax1.plot(monitor_data.index, errors, color=COLORS['blue'], lw=0.8, alpha=0.7)\n",
    "ax1.axhline(0, color=COLORS['gray'], ls='-', lw=1)\n",
    "ax1.axhline(np.mean(errors[:100]) + 2*np.std(errors[:100]), color=COLORS['orange'], ls='--', lw=1, label='+2 std')\n",
    "ax1.axhline(np.mean(errors[:100]) - 2*np.std(errors[:100]), color=COLORS['orange'], ls='--', lw=1, label='-2 std')\n",
    "\n",
    "# Highlight drift periods\n",
    "ax1.fill_between(monitor_data.index, ax1.get_ylim()[0], ax1.get_ylim()[1],\n",
    "                 where=drift_alerts, color=COLORS['red'], alpha=0.2, label='Drift Alert')\n",
    "\n",
    "ax1.set_ylabel('Prediction Error (EUR/MWh)')\n",
    "ax1.set_title('Prediction Errors with Control Limits', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Panel 2: CUSUM chart\n",
    "ax2 = axes[1]\n",
    "ax2.plot(monitor_data.index, cusum_pos, color=COLORS['green'], lw=1.5, label='CUSUM+ (positive shift)')\n",
    "ax2.plot(monitor_data.index, cusum_neg, color=COLORS['red'], lw=1.5, label='CUSUM- (negative shift)')\n",
    "ax2.axhline(4.0, color=COLORS['gray'], ls='--', lw=1.5, label='Alert Threshold')\n",
    "\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.set_ylabel('CUSUM Value')\n",
    "ax2.set_title('CUSUM Control Chart for Concept Drift', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper left', frameon=False)\n",
    "\n",
    "fig.suptitle('Concept Drift Detection using CUSUM', fontsize=15, fontweight='bold', y=1.01)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Importance Stability\n",
    "\n",
    "Monitor how feature importances change over time.\n",
    "Large shifts indicate the model may be relying on unstable relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance for different time periods\n",
    "def get_importance_for_period(X, y):\n",
    "    \"\"\"Train RF and return feature importances.\"\"\"\n",
    "    rf = RandomForestRegressor(n_estimators=50, max_depth=6, random_state=42, n_jobs=-1)\n",
    "    rf.fit(X, y)\n",
    "    return pd.Series(rf.feature_importances_, index=X.columns)\n",
    "\n",
    "# Training period importance\n",
    "imp_train = get_importance_for_period(X_train, y_train)\n",
    "\n",
    "# Importance for each monitoring quarter\n",
    "imp_quarters = {}\n",
    "for q_name, q_data in quarters:\n",
    "    X_q = q_data[feature_cols]\n",
    "    y_q = q_data['target']\n",
    "    imp_quarters[q_name] = get_importance_for_period(X_q, y_q)\n",
    "\n",
    "# Combine into dataframe\n",
    "imp_df = pd.DataFrame({'Training': imp_train})\n",
    "for q_name, imp in imp_quarters.items():\n",
    "    imp_df[q_name] = imp\n",
    "\n",
    "# Calculate importance rank changes\n",
    "rank_train = imp_df['Training'].rank(ascending=False)\n",
    "rank_q4 = imp_df['Q4'].rank(ascending=False)\n",
    "rank_change = (rank_train - rank_q4).abs()\n",
    "\n",
    "print(\"Feature Importance Stability (rank change from Training to Q4):\")\n",
    "print(rank_change.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance evolution\n",
    "top_features = imp_df['Training'].nlargest(8).index.tolist()\n",
    "imp_subset = imp_df.loc[top_features]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "x = np.arange(len(imp_subset.columns))\n",
    "width = 0.10\n",
    "\n",
    "colors = [COLORS['blue'], COLORS['green'], COLORS['orange'], COLORS['red'], COLORS['purple']]\n",
    "\n",
    "for i, feat in enumerate(top_features):\n",
    "    offset = (i - len(top_features)/2) * width\n",
    "    bars = ax.bar(x + offset, imp_subset.loc[feat].values, width, label=feat, alpha=0.85)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(imp_subset.columns)\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Feature Importance')\n",
    "ax.set_title('Feature Importance Evolution Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.12), frameon=False, ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Recalibration Trigger Summary\n",
    "\n",
    "Combine all monitoring signals into a dashboard for decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate summary metrics for each quarter\n",
    "summary_results = []\n",
    "\n",
    "for q_name, q_data in quarters:\n",
    "    q_idx = q_data.index\n",
    "    q_mask = monitor_data.index.isin(q_idx)\n",
    "    q_errors = errors[q_mask]\n",
    "    \n",
    "    # Performance metrics\n",
    "    q_mae = np.mean(np.abs(q_errors))\n",
    "    q_rmse = np.sqrt(np.mean(q_errors**2))\n",
    "    \n",
    "    # Drift metrics\n",
    "    psi_vals = drift_df[drift_df['Period'] == q_name]['PSI'].values\n",
    "    max_psi = psi_vals.max() if len(psi_vals) > 0 else 0\n",
    "    \n",
    "    # CUSUM alerts in this quarter\n",
    "    q_alerts = drift_alerts[q_mask].sum()\n",
    "    \n",
    "    # Performance degradation\n",
    "    mae_ratio = q_mae / baseline_mae\n",
    "    \n",
    "    # Recalibration trigger logic\n",
    "    triggers = []\n",
    "    if mae_ratio > 1.5:\n",
    "        triggers.append('Performance')\n",
    "    if max_psi > 0.2:\n",
    "        triggers.append('Data Drift')\n",
    "    if q_alerts > len(q_errors) * 0.1:\n",
    "        triggers.append('Concept Drift')\n",
    "    \n",
    "    summary_results.append({\n",
    "        'Period': q_name,\n",
    "        'Date Range': f\"{q_idx.min().strftime('%Y-%m')} to {q_idx.max().strftime('%Y-%m')}\",\n",
    "        'MAE': q_mae,\n",
    "        'MAE Ratio': mae_ratio,\n",
    "        'Max PSI': max_psi,\n",
    "        'CUSUM Alerts': q_alerts,\n",
    "        'Triggers': ', '.join(triggers) if triggers else 'None',\n",
    "        'Action': 'RETRAIN' if triggers else 'Monitor'\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"   MODEL MONITORING SUMMARY\")\n",
    "print(\"=\"*90)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final monitoring dashboard visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "periods = summary_df['Period'].tolist()\n",
    "x = np.arange(len(periods))\n",
    "\n",
    "# Color by action\n",
    "action_colors = [COLORS['red'] if a == 'RETRAIN' else COLORS['green'] for a in summary_df['Action']]\n",
    "\n",
    "# Panel 1: MAE Ratio\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.bar(x, summary_df['MAE Ratio'], color=action_colors, alpha=0.85, edgecolor='white')\n",
    "ax1.axhline(1.0, color=COLORS['green'], ls='--', lw=1.5, label='Baseline')\n",
    "ax1.axhline(1.5, color=COLORS['red'], ls='--', lw=1.5, label='Alert Threshold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(periods)\n",
    "ax1.set_ylabel('MAE Ratio (vs Training)')\n",
    "ax1.set_title('Performance Degradation', fontsize=13, fontweight='bold')\n",
    "ax1.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Panel 2: Max PSI\n",
    "ax2 = axes[0, 1]\n",
    "bars = ax2.bar(x, summary_df['Max PSI'], color=action_colors, alpha=0.85, edgecolor='white')\n",
    "ax2.axhline(0.1, color=COLORS['orange'], ls='--', lw=1.5, label='Monitor')\n",
    "ax2.axhline(0.2, color=COLORS['red'], ls='--', lw=1.5, label='Alert')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(periods)\n",
    "ax2.set_ylabel('Maximum PSI')\n",
    "ax2.set_title('Data Drift (PSI)', fontsize=13, fontweight='bold')\n",
    "ax2.legend(loc='upper right', frameon=False)\n",
    "\n",
    "# Panel 3: CUSUM Alerts\n",
    "ax3 = axes[1, 0]\n",
    "bars = ax3.bar(x, summary_df['CUSUM Alerts'], color=action_colors, alpha=0.85, edgecolor='white')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(periods)\n",
    "ax3.set_ylabel('Number of Alerts')\n",
    "ax3.set_title('Concept Drift Alerts', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Panel 4: Action Summary (traffic light)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# Create text summary\n",
    "summary_text = \"MODEL HEALTH SUMMARY\\n\" + \"=\"*35 + \"\\n\\n\"\n",
    "for _, row in summary_df.iterrows():\n",
    "    status = \"OK\" if row['Action'] == 'Monitor' else \"ALERT\"\n",
    "    symbol = \"[OK]\" if status == \"OK\" else \"[!!]\"\n",
    "    summary_text += f\"{symbol} {row['Period']}: {row['Action']}\\n\"\n",
    "    if row['Triggers'] != 'None':\n",
    "        summary_text += f\"    Triggers: {row['Triggers']}\\n\"\n",
    "\n",
    "summary_text += \"\\n\" + \"=\"*35 + \"\\n\"\n",
    "summary_text += \"\\nRecalibration Thresholds:\\n\"\n",
    "summary_text += \"  - MAE Ratio > 1.5\\n\"\n",
    "summary_text += \"  - Max PSI > 0.2\\n\"\n",
    "summary_text += \"  - CUSUM Alerts > 10%\\n\"\n",
    "\n",
    "ax4.text(0.1, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n",
    "         verticalalignment='top', fontfamily='monospace',\n",
    "         bbox=dict(boxstyle='round', facecolor='white', alpha=0.9, edgecolor=COLORS['gray']))\n",
    "\n",
    "fig.suptitle('Model Monitoring Dashboard', fontsize=15, fontweight='bold', y=1.01)\n",
    "fig.tight_layout()\n",
    "save_fig(fig, 'ml_monitor.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final recommendations\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"   MONITORING RECOMMENDATIONS\")\n",
    "print(\"=\"*70)\n",
    "print(\"\"\"\n",
    "1. PERFORMANCE MONITORING\n",
    "   - Track rolling MAE/RMSE with 30-day windows\n",
    "   - Alert when MAE exceeds 1.5x training baseline\n",
    "   - Monitor prediction bias for systematic errors\n",
    "\n",
    "2. DATA DRIFT DETECTION\n",
    "   - Calculate PSI for key features weekly\n",
    "   - PSI > 0.2 indicates significant distribution shift\n",
    "   - Use KS-test for additional validation\n",
    "\n",
    "3. CONCEPT DRIFT DETECTION\n",
    "   - Implement CUSUM control charts on prediction errors\n",
    "   - Monitor feature importance stability\n",
    "   - Track residual distribution changes\n",
    "\n",
    "4. RECALIBRATION TRIGGERS\n",
    "   - Automatic retrain when any threshold is breached\n",
    "   - Minimum retrain frequency: monthly\n",
    "   - Maximum retrain frequency: weekly (avoid overfitting to noise)\n",
    "\n",
    "5. BEST PRACTICES FOR ENERGY MARKETS\n",
    "   - Expect drift during seasonal transitions\n",
    "   - Monitor market regime changes (high volatility periods)\n",
    "   - Consider rolling retraining with expanding windows\n",
    "\"\"\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
