{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EN/quantlets/EMQA_ml_compare/EMQA_ml_compare.ipynb)\n\n# EMQA_ml_compare\nML model comparison: Linear Regression, Random Forest, Gradient Boosting.\n**Output:** `ml_compare.pdf`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams.update({\n    'figure.facecolor': 'none',\n    'axes.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.transparent': True,\n    'axes.grid': False,\n    'axes.spines.top': False,\n    'axes.spines.right': False,\n    'font.size': 11,\n    'figure.figsize': (12, 6),\n})\n\nCOLORS = {\n    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n    'cyan': '#00BCD4', 'amber': '#B5853F'\n}\n\ndef save_fig(fig, name):\n    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n    print(f\"Saved: {name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import yfinance as yf\n\ndef fetch(ticker, start='2020-01-01', end='2025-12-31'):\n    d = yf.download(ticker, start=start, end=end, progress=False)\n    if isinstance(d.columns, pd.MultiIndex):\n        return d['Close'].squeeze().dropna()\n    return d['Close'].dropna()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Fetch Brent and create features (same as ml_rf)\nbrent = fetch('BZ=F', start='2018-01-01')\ndf = pd.DataFrame({'price': brent})\ndf['return'] = np.log(df['price'] / df['price'].shift(1))\n\nfor lag in [1, 2, 3, 7, 14]:\n    df[f'ret_lag_{lag}'] = df['return'].shift(lag)\n\ndf['roll_mean_5'] = df['return'].rolling(5).mean()\ndf['roll_std_5'] = df['return'].rolling(5).std()\ndf['roll_mean_20'] = df['return'].rolling(20).mean()\ndf['roll_std_20'] = df['return'].rolling(20).std()\ndf['roll_skew_20'] = df['return'].rolling(20).skew()\n\ndf['target'] = df['return'].shift(-1)\ndf = df.dropna()\n\nfeature_cols = [c for c in df.columns if c not in ['price', 'return', 'target']]\nX = df[feature_cols].values\ny = df['target'].values\n\nsplit = int(len(X) * 0.8)\nX_train, X_test = X[:split], X[split:]\ny_train, y_test = y[:split], y[split:]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\nmodels = {\n    'Linear Regression': LinearRegression(),\n    'Random Forest': RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1),\n    'Gradient Boosting': GradientBoostingRegressor(n_estimators=200, max_depth=5, random_state=42),\n}\n\nresults = {}\nfor name_m, model in models.items():\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mae = mean_absolute_error(y_test, y_pred)\n    r2 = r2_score(y_test, y_pred)\n\n    # Simple directional Sharpe proxy\n    pred_sign = np.sign(y_pred)\n    strat_ret = pred_sign * y_test\n    sharpe = strat_ret.mean() / strat_ret.std() * np.sqrt(252) if strat_ret.std() > 0 else 0\n\n    results[name_m] = {'MAE': mae, 'R2': r2, 'Sharpe': sharpe}\n    print(f\"{name_m}: MAE={mae:.6f}, R2={r2:.4f}, Sharpe={sharpe:.2f}\")\n\nres_df = pd.DataFrame(results).T"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\nbar_colors = [COLORS['blue'], COLORS['green'], COLORS['orange']]\n\n# Panel 1 - MAE\nbars1 = axes[0].bar(res_df.index, res_df['MAE'], color=bar_colors, width=0.5, edgecolor='white')\nfor bar, val in zip(bars1, res_df['MAE']):\n    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.00005,\n                 f'{val:.5f}', ha='center', va='bottom', fontsize=10)\naxes[0].set_ylabel('MAE')\naxes[0].set_title('Mean Absolute Error')\naxes[0].tick_params(axis='x', rotation=15)\n\n# Panel 2 - R-squared\nbars2 = axes[1].bar(res_df.index, res_df['R2'], color=bar_colors, width=0.5, edgecolor='white')\nfor bar, val in zip(bars2, res_df['R2']):\n    offset = 0.002 if val >= 0 else -0.002\n    va = 'bottom' if val >= 0 else 'top'\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + offset,\n                 f'{val:.4f}', ha='center', va=va, fontsize=10)\naxes[1].set_ylabel('$R^2$')\naxes[1].set_title('R-squared')\naxes[1].tick_params(axis='x', rotation=15)\naxes[1].axhline(0, color=COLORS['gray'], linestyle=':', linewidth=0.8)\n\nplt.tight_layout()\nsave_fig(fig, 'ml_compare.pdf')\nplt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}