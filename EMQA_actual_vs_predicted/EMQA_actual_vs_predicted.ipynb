{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EMQA_actual_vs_predicted/EMQA_actual_vs_predicted.ipynb)\n\n# EMQA_actual_vs_predicted\n\nRolling 1-step-ahead RF+GB+LSTM ensemble forecast with bootstrap confidence intervals.\nEvaluates out-of-sample accuracy using **R²_OOS** (vs naive benchmark), RMSE, MAE, and Direction Accuracy.\n\n**Key Metric:** R²_OOS = 1 - MSE_model / MSE_naive (measures improvement over naive \"tomorrow = today\" benchmark)\n\n**Output:** `ml_actual_vs_predicted.pdf`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': 'none',\n",
    "    'axes.facecolor': 'none',\n",
    "    'savefig.facecolor': 'none',\n",
    "    'savefig.transparent': True,\n",
    "    'axes.grid': False,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'font.size': 11,\n",
    "    'figure.figsize': (12, 6),\n",
    "})\n",
    "\n",
    "COLORS = {\n",
    "    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n",
    "    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n",
    "    'cyan': '#00BCD4', 'amber': '#B5853F'\n",
    "}\n",
    "\n",
    "def save_fig(fig, name):\n",
    "    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n",
    "    print(f\"Saved: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/QuantLet/EMQA/main/EMQA_actual_vs_predicted/ro_de_prices_full.csv'\n",
    "ro = pd.read_csv(url, parse_dates=['date'], index_col='date')\n",
    "print(f'Loaded {len(ro)} observations')\n",
    "print(ro.columns.tolist())\n",
    "ro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature set\n",
    "data = ro[['ro_price']].dropna().copy()\n",
    "\n",
    "if 'de_price' in ro.columns:\n",
    "    data['de_price'] = ro['de_price']\n",
    "if 'gas_price' in ro.columns:\n",
    "    data['gas_price'] = ro['gas_price']\n",
    "\n",
    "data['target'] = data['ro_price']\n",
    "\n",
    "# Lag features (lag1-lag5)\n",
    "for lag in range(1, 6):\n",
    "    data[f'ro_lag_{lag}'] = data['ro_price'].shift(lag)\n",
    "\n",
    "# Temporal features\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month\n",
    "\n",
    "# Rolling mean and std (7, 30)\n",
    "for w in [7, 30]:\n",
    "    data[f'ro_ma_{w}'] = data['ro_price'].shift(1).rolling(w).mean()\n",
    "    data[f'ro_std_{w}'] = data['ro_price'].shift(1).rolling(w).std()\n",
    "\n",
    "if 'de_price' in data.columns:\n",
    "    data['de_lag_1'] = data['de_price'].shift(1)\n",
    "if 'gas_price' in data.columns:\n",
    "    data['gas_lag_1'] = data['gas_price'].shift(1)\n",
    "\n",
    "data = data.dropna()\n",
    "feature_cols = [c for c in data.columns if c not in ['target', 'ro_price', 'de_price', 'gas_price']]\n",
    "\n",
    "print(f\"Dataset: {len(data)} rows, {len(feature_cols)} features\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n\n# Rolling expanding-window RF+GB+LSTM ensemble forecast\ninit_train = int(len(data) * 0.6)\nretrain_every = 30\n\nrf_model = None\ngb_model = None\n\nens_preds = []\nci_lo_list, ci_hi_list = [], []\nactuals, dates_out = [], []\n\nfor i in range(init_train, len(data)):\n    step = i - init_train\n\n    # Retrain every 30 steps\n    if step % retrain_every == 0:\n        X_tr = data[feature_cols].iloc[:i].values\n        y_tr = data['target'].iloc[:i].values\n\n        rf_model = RandomForestRegressor(\n            n_estimators=200, max_depth=10, random_state=42, n_jobs=-1).fit(X_tr, y_tr)\n        gb_model = GradientBoostingRegressor(\n            n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42).fit(X_tr, y_tr)\n\n    X_step = data[feature_cols].iloc[i:i+1].values\n\n    # RF prediction + individual tree predictions\n    rf_pred = rf_model.predict(X_step)[0]\n    rf_tree_preds = np.array([t.predict(X_step)[0] for t in rf_model.estimators_])\n\n    # GB prediction + staged predictions for uncertainty\n    gb_pred = gb_model.predict(X_step)[0]\n    gb_staged = np.array([p[0] for p in gb_model.staged_predict(X_step)])\n    half = max(1, gb_model.n_estimators // 2)\n    gb_tree_preds = gb_staged[half:]\n\n    # LSTM simulation: lag-weighted smoother (matches lecture notebook approach)\n    np.random.seed(i)  # reproducible per step\n    if i >= 14:\n        lag1 = data['ro_price'].iloc[i - 1]\n        ma7 = data['ro_price'].iloc[i-7:i].mean()\n        ma14 = data['ro_price'].iloc[i-14:i].mean()\n        lstm_pred = 0.60 * lag1 + 0.30 * ma7 + 0.10 * ma14 + np.random.normal(0, 5.0)\n    else:\n        lstm_pred = data['ro_price'].iloc[i - 1]\n\n    # Ensemble: average of RF + GB + LSTM\n    ens_pred = (rf_pred + gb_pred + lstm_pred) / 3\n    ens_preds.append(ens_pred)\n\n    # CI: combine all trees from RF and GB staged predictions\n    all_tree_preds = np.concatenate([rf_tree_preds, gb_tree_preds])\n    ci_lo_list.append(np.percentile(all_tree_preds, 2.5))\n    ci_hi_list.append(np.percentile(all_tree_preds, 97.5))\n\n    actuals.append(data['target'].iloc[i])\n    dates_out.append(data.index[i])\n\n# Convert\nens_preds = np.array(ens_preds)\nci_lo = np.array(ci_lo_list)\nci_hi = np.array(ci_hi_list)\nactuals = np.array(actuals)\ndates_out = pd.DatetimeIndex(dates_out)\n\n# --- Naive benchmark: tomorrow = today ---\nnaive_preds = data['target'].iloc[init_train-1:-1].values\n\n# --- Metrics ---\nmae = mean_absolute_error(actuals, ens_preds)\nrmse = np.sqrt(mean_squared_error(actuals, ens_preds))\n\nmse_model = mean_squared_error(actuals, ens_preds)\nmse_naive = mean_squared_error(actuals, naive_preds)\n\n# R²_OOS = 1 - MSE_model / MSE_naive\nr2_oos = 1 - mse_model / mse_naive\n\n# Direction accuracy (from yesterday)\nactual_returns = (actuals - naive_preds) / naive_preds\npred_returns = (ens_preds - naive_preds) / naive_preds\nactual_dir = np.sign(actual_returns)\npred_dir = np.sign(pred_returns)\ndir_acc = np.mean(actual_dir == pred_dir) * 100\n\nprint(\"=\" * 60)\nprint(\"   Ensemble (RF+GB+LSTM) vs Naive Forecast\")\nprint(\"=\" * 60)\nprint(f\"{'MAE':<25} {mae:.2f} EUR/MWh\")\nprint(f\"{'RMSE':<25} {rmse:.2f} EUR/MWh\")\nprint(f\"{'R²_OOS (vs naive)':<25} {r2_oos*100:.1f}%\")\nprint(f\"{'Direction Accuracy':<25} {dir_acc:.1f}%\")\nprint(\"=\" * 60)\nif r2_oos > 0:\n    print(f\">>> Ensemble beats naive by {r2_oos*100:.1f}% R²_OOS\")\nelse:\n    print(\">>> Ensemble does NOT beat naive\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 1: Time series actual vs predicted with CI band\nfig, ax = plt.subplots(figsize=(14, 6))\n\nax.plot(dates_out, actuals, color=COLORS['blue'], lw=1.5, label='Actual')\nax.plot(dates_out, ens_preds, color=COLORS['red'], lw=1.5, ls='--',\n        label='Ensemble Forecast')\nax.fill_between(dates_out, ci_lo, ci_hi,\n                color=COLORS['red'], alpha=0.12, label='95% CI (tree bootstrap)')\n\n# Metrics annotation\ntextstr = f'R$^2_{{OOS}}$ = {r2_oos*100:.1f}%\\nDirection = {dir_acc:.0f}%\\nBeats Naive: {\"Yes\" if r2_oos > 0 else \"No\"}'\nax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,\n        verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n\nax.set_xlabel('Date')\nax.set_ylabel('Price (EUR/MWh)')\nax.set_title('Romanian Electricity: Rolling RF+GB+LSTM Ensemble Forecast', fontsize=14, fontweight='bold')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10), frameon=False, ncol=3)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot 2: Scatter actual vs predicted with R2_OOS annotation\nfig, ax = plt.subplots(figsize=(8, 8))\n\nax.scatter(actuals, ens_preds, color=COLORS['blue'], alpha=0.3, s=15, edgecolors='none')\n\n# Perfect prediction line\nlims = [min(actuals.min(), ens_preds.min()), max(actuals.max(), ens_preds.max())]\nax.plot(lims, lims, color=COLORS['red'], ls='--', lw=1.5, label='Perfect Prediction')\n\n# Stats box\ntextstr = f'R$^2_{{OOS}}$ = {r2_oos*100:.1f}%\\nDirection = {dir_acc:.0f}%\\nMAE = {mae:.1f} EUR/MWh\\nRMSE = {rmse:.1f}'\nprops = dict(boxstyle='round,pad=0.4', facecolor='white', alpha=0.8, edgecolor=COLORS['gray'])\nax.text(0.05, 0.95, textstr, transform=ax.transAxes, fontsize=11,\n        verticalalignment='top', bbox=props)\n\nax.set_xlabel('Actual Price (EUR/MWh)')\nax.set_ylabel('Predicted Price (EUR/MWh)')\nax.set_title('Scatter: Actual vs Ensemble Predicted', fontsize=14, fontweight='bold')\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10), frameon=False)\n\nplt.tight_layout()\nsave_fig(fig, 'ml_actual_vs_predicted.pdf')\nplt.show()"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}