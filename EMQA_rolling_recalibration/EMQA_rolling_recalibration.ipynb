{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EMQA_rolling_recalibration/EMQA_rolling_recalibration.ipynb)\n\n# EMQA_rolling_recalibration\n\nStatic vs monthly retrained (rolling recalibration) model comparison with bootstrap confidence intervals from Random Forest trees.\n\n**Output:** `ml_rolling_recalibration.pdf`"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams.update({\n    'figure.facecolor': 'none',\n    'axes.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.transparent': True,\n    'axes.grid': False,\n    'axes.spines.top': False,\n    'axes.spines.right': False,\n    'font.size': 11,\n    'figure.figsize': (12, 6),\n})\n\nCOLORS = {\n    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n    'cyan': '#00BCD4', 'amber': '#B5853F'\n}\n\ndef save_fig(fig, name):\n    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n    print(f\"Saved: {name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "url = 'https://raw.githubusercontent.com/QuantLet/EMQA/main/EMQA_rolling_recalibration/ro_de_prices_full.csv'\n",
    "ro = pd.read_csv(url, parse_dates=['date'], index_col='date')\n",
    "print(f'Loaded {len(ro)} observations')\n",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ndata = ro[['ro_price', 'de_price']].dropna().copy()\ndata['target'] = data['ro_price']\n\n# Lagged features\nfor lag in [1, 2, 7, 14, 30]:\n    data[f'ro_lag_{lag}'] = data['ro_price'].shift(lag)\nfor lag in [1, 7]:\n    data[f'de_lag_{lag}'] = data['de_price'].shift(lag)\n\n# Rolling stats\nfor w in [7, 14, 30]:\n    data[f'ro_ma_{w}'] = data['ro_price'].shift(1).rolling(w).mean()\n    data[f'ro_std_{w}'] = data['ro_price'].shift(1).rolling(w).std()\n\n# Temporal\ndata['dow'] = data.index.dayofweek\ndata['month'] = data.index.month\ndata['weekend'] = (data.index.dayofweek >= 5).astype(int)\n\ndata = data.dropna()\nfeature_cols = [c for c in data.columns if c not in ['target', 'ro_price', 'de_price']]\n\nprint(f\"Dataset: {len(data)} rows, {len(feature_cols)} features\")\nprint(f\"Features: {feature_cols}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- Static model: trained once on first 70% ---\nsplit = int(len(data) * 0.7)\ntest_start = max(split, len(data) - 120)  # last 120 days for test\n\nX_all = data[feature_cols]\ny_all = data['target']\n\nX_train_static = X_all.iloc[:split]\ny_train_static = y_all.iloc[:split]\n\nX_test_period = X_all.iloc[test_start:]\ny_test_period = y_all.iloc[test_start:]\n\n# Static RF\nrf_static = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=42, n_jobs=-1)\nrf_static.fit(X_train_static, y_train_static)\nstatic_pred = pd.Series(rf_static.predict(X_test_period), index=y_test_period.index)\n\n# Bootstrap CI from static RF trees\nstatic_tree_preds = np.array([tree.predict(X_test_period.values)\n                               for tree in rf_static.estimators_])\nstatic_ci_lower = pd.Series(np.percentile(static_tree_preds, 2.5, axis=0), index=y_test_period.index)\nstatic_ci_upper = pd.Series(np.percentile(static_tree_preds, 97.5, axis=0), index=y_test_period.index)\n\n# --- Rolling model: retrained every 30 days with expanding window ---\nrolling_pred = pd.Series(dtype=float, index=y_test_period.index)\nrolling_ci_lower = pd.Series(dtype=float, index=y_test_period.index)\nrolling_ci_upper = pd.Series(dtype=float, index=y_test_period.index)\nrecalib_dates = []\n\ntest_indices = list(range(test_start, len(data)))\nchunk_size = 30\n\nfor chunk_start_idx in range(0, len(test_indices), chunk_size):\n    chunk_end_idx = min(chunk_start_idx + chunk_size, len(test_indices))\n    idx_slice = test_indices[chunk_start_idx:chunk_end_idx]\n\n    # Expanding training window up to current chunk start\n    train_end = test_indices[chunk_start_idx]\n    X_tr = X_all.iloc[:train_end]\n    y_tr = y_all.iloc[:train_end]\n\n    rf_roll = RandomForestRegressor(n_estimators=150, max_depth=10, random_state=42, n_jobs=-1)\n    rf_roll.fit(X_tr, y_tr)\n\n    X_chunk = X_all.iloc[idx_slice]\n    preds = rf_roll.predict(X_chunk)\n    rolling_pred.iloc[chunk_start_idx:chunk_end_idx] = preds\n\n    # Bootstrap CI from individual tree predictions\n    tree_preds = np.array([tree.predict(X_chunk.values) for tree in rf_roll.estimators_])\n    rolling_ci_lower.iloc[chunk_start_idx:chunk_end_idx] = np.percentile(tree_preds, 2.5, axis=0)\n    rolling_ci_upper.iloc[chunk_start_idx:chunk_end_idx] = np.percentile(tree_preds, 97.5, axis=0)\n\n    recalib_dates.append(data.index[test_indices[chunk_start_idx]])\n\nprint(f\"Recalibration dates: {len(recalib_dates)}\")\nfor d in recalib_dates:\n    print(f\"  {d.strftime('%Y-%m-%d')}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- Metrics ---\nmask = rolling_pred.notna()\n\nmae_static = mean_absolute_error(y_test_period[mask], static_pred[mask])\nmae_rolling = mean_absolute_error(y_test_period[mask], rolling_pred[mask])\nr2_static = r2_score(y_test_period[mask], static_pred[mask])\nr2_rolling = r2_score(y_test_period[mask], rolling_pred[mask])\n\n# Direction accuracy\ndef direction_accuracy(actual, predicted):\n    actual_dir = actual.diff().dropna() > 0\n    pred_dir = predicted.diff().dropna() > 0\n    common = actual_dir.index.intersection(pred_dir.index)\n    return (actual_dir[common] == pred_dir[common]).mean()\n\nda_static = direction_accuracy(y_test_period[mask], static_pred[mask])\nda_rolling = direction_accuracy(y_test_period[mask], rolling_pred[mask])\n\n# CI coverage\ncov_static = np.mean((y_test_period[mask].values >= static_ci_lower[mask].values) &\n                      (y_test_period[mask].values <= static_ci_upper[mask].values)) * 100\ncov_rolling = np.mean((y_test_period[mask].values >= rolling_ci_lower[mask].values) &\n                       (y_test_period[mask].values <= rolling_ci_upper[mask].values)) * 100\n\nprint(f\"Static  - MAE: {mae_static:.2f}, R2: {r2_static:.4f}, Dir Acc: {da_static:.3f}, 95% CI Coverage: {cov_static:.1f}%\")\nprint(f\"Rolling - MAE: {mae_rolling:.2f}, R2: {r2_rolling:.4f}, Dir Acc: {da_rolling:.3f}, 95% CI Coverage: {cov_rolling:.1f}%\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# --- 2-panel chart ---\nfig, axes = plt.subplots(1, 2, figsize=(16, 6), gridspec_kw={'width_ratios': [2, 1]})\n\n# (A) Time series with CIs\nax = axes[0]\nax.plot(y_test_period.index, y_test_period.values, color=COLORS['blue'], lw=1.5, label='Actual')\nax.plot(static_pred.index, static_pred.values, color=COLORS['orange'], lw=1.2, ls='--',\n        alpha=0.8, label='Static Model')\nax.fill_between(static_pred.index, static_ci_lower.values, static_ci_upper.values,\n                color=COLORS['orange'], alpha=0.10, label='Static 95% CI')\nax.plot(rolling_pred.index, rolling_pred.values, color=COLORS['green'], lw=1.5, ls='-',\n        alpha=0.9, label='Rolling Model')\nax.fill_between(rolling_pred.index, rolling_ci_lower.values, rolling_ci_upper.values,\n                color=COLORS['green'], alpha=0.12, label='Rolling 95% CI')\n\nfor rd in recalib_dates:\n    ax.axvline(rd, color=COLORS['red'], ls=':', lw=0.8, alpha=0.6)\n# One label for recalibration lines\nax.axvline(recalib_dates[0], color=COLORS['red'], ls=':', lw=0.8, alpha=0.6, label='Recalibration')\n\nax.set_title('(A) Actual vs Static vs Rolling Predictions', fontsize=13, fontweight='bold')\nax.set_xlabel('Date')\nax.set_ylabel('Price (EUR/MWh)')\nax.tick_params(axis='x', rotation=30)\nax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), frameon=False, ncol=3)\n\n# (B) Bar chart: MAE, R2, Direction Accuracy\nax2 = axes[1]\nmetrics = ['MAE', 'R$^2$', 'Dir. Acc.']\nstatic_vals = [mae_static, r2_static, da_static]\nrolling_vals = [mae_rolling, r2_rolling, da_rolling]\n\nx = np.arange(len(metrics))\nwidth = 0.32\n\nbars1 = ax2.bar(x - width/2, static_vals, width, color=COLORS['orange'], alpha=0.8, label='Static')\nbars2 = ax2.bar(x + width/2, rolling_vals, width, color=COLORS['green'], alpha=0.8, label='Rolling')\n\nfor bar, val in zip(bars1, static_vals):\n    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n             f'{val:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\nfor bar, val in zip(bars2, rolling_vals):\n    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n             f'{val:.3f}', ha='center', va='bottom', fontsize=9, fontweight='bold')\n\nax2.set_xticks(x)\nax2.set_xticklabels(metrics, fontsize=11)\nax2.set_title('(B) Metric Comparison', fontsize=13, fontweight='bold')\nax2.legend(loc='upper center', bbox_to_anchor=(0.5, -0.10), frameon=False, ncol=2)\n\nfig.suptitle('Static vs Rolling Recalibration', fontsize=15, fontweight='bold', y=1.02)\nfig.tight_layout()\nsave_fig(fig, 'ml_rolling_recalibration.pdf')\nplt.show()",
   "outputs": [],
   "execution_count": null
  }
 ]
}