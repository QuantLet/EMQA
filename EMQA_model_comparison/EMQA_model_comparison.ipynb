{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/EMQA/blob/main/EMQA_model_comparison/EMQA_model_comparison.ipynb)\n\n# EMQA_model_comparison\n\nML model comparison (Naive, Random Forest, Gradient Boosting, Ensemble) on Romanian electricity price data.\n\n**Output:** `ml_model_comparison.pdf`\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams.update({\n    'figure.facecolor': 'none',\n    'axes.facecolor': 'none',\n    'savefig.facecolor': 'none',\n    'savefig.transparent': True,\n    'axes.grid': False,\n    'axes.spines.top': False,\n    'axes.spines.right': False,\n    'font.size': 11,\n    'figure.figsize': (12, 6),\n})\n\nCOLORS = {\n    'blue': '#1A3A6E', 'red': '#CD0000', 'green': '#2E7D32',\n    'orange': '#E67E22', 'purple': '#8E44AD', 'gray': '#808080',\n    'cyan': '#00BCD4', 'amber': '#B5853F'\n}\n\ndef save_fig(fig, name):\n    fig.savefig(name, bbox_inches='tight', transparent=True, dpi=300)\n    print(f\"Saved: {name}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "url = 'https://raw.githubusercontent.com/QuantLet/EMQA/main/EMQA_model_comparison/ro_de_prices_full.csv'\n",
    "ro = pd.read_csv(url, parse_dates=['date'], index_col='date')\n",
    "print(f'Loaded {len(ro)} observations')\n",
    ""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_absolute_error, r2_score\n\ndf = load_ro_de()\ndata = df[['ro_price', 'de_price']].dropna().copy()\ndata['target'] = data['ro_price']\n\n# Lagged features\nfor lag in [1, 2, 7, 14, 30]:\n    data[f'ro_lag_{lag}'] = data['ro_price'].shift(lag)\nfor lag in [1, 7]:\n    data[f'de_lag_{lag}'] = data['de_price'].shift(lag)\n\n# Rolling stats\nfor w in [7, 14, 30]:\n    data[f'ro_ma_{w}'] = data['ro_price'].shift(1).rolling(w).mean()\n    data[f'ro_std_{w}'] = data['ro_price'].shift(1).rolling(w).std()\n\n# Temporal\ndata['dow'] = data.index.dayofweek\ndata['month'] = data.index.month\ndata['weekend'] = (data.index.dayofweek >= 5).astype(int)\n\ndata = data.dropna()\nfeature_cols = [c for c in data.columns if c not in ['target', 'ro_price', 'de_price']]\n\nprint(f\"Dataset: {len(data)} rows, {len(feature_cols)} features\")\nprint(f\"Features: {feature_cols}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Train/test split (time series: 70/30) ---\nsplit = int(len(data) * 0.7)\nX_train, X_test = data[feature_cols].iloc[:split], data[feature_cols].iloc[split:]\ny_train, y_test = data['target'].iloc[:split], data['target'].iloc[split:]\n\nprint(f\"Train: {len(X_train)}, Test: {len(X_test)}\")\n\n# --- Models ---\n# Naive baseline: lag-1\nnaive_pred = data['ro_price'].shift(1).iloc[split:].reindex(y_test.index)\n\n# Random Forest\nrf = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)\nrf.fit(X_train, y_train)\nrf_pred = pd.Series(rf.predict(X_test), index=y_test.index)\n\n# Gradient Boosting\ngb = GradientBoostingRegressor(n_estimators=200, max_depth=5, learning_rate=0.1, random_state=42)\ngb.fit(X_train, y_train)\ngb_pred = pd.Series(gb.predict(X_test), index=y_test.index)\n\n# Simple average ensemble\nens_pred = (rf_pred + gb_pred) / 2\n\n# --- Metrics ---\nmodels = {\n    'Naive (lag-1)': naive_pred,\n    'Random Forest': rf_pred,\n    'GradientBoosting': gb_pred,\n    'Ensemble (Avg)': ens_pred,\n}\n\nresults = {}\nfor name, pred in models.items():\n    mask = pred.notna() & y_test.notna()\n    mae = mean_absolute_error(y_test[mask], pred[mask])\n    r2 = r2_score(y_test[mask], pred[mask])\n    results[name] = {'MAE': mae, 'R2': r2}\n    print(f\"{name:20s}  MAE={mae:.2f}  R2={r2:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# --- Chart: 1x2 MAE and R2 bars ---\nmodel_names = list(results.keys())\nmaes = [results[m]['MAE'] for m in model_names]\nr2s = [results[m]['R2'] for m in model_names]\nbar_colors = [COLORS['gray'], COLORS['green'], COLORS['purple'], COLORS['red']]\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\n\n# (A) MAE\nax = axes[0]\nbars = ax.bar(model_names, maes, color=bar_colors, alpha=0.8, edgecolor='white', lw=1.5)\nfor bar, val in zip(bars, maes):\n    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3,\n            f'{val:.1f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\nax.set_title('(A) Mean Absolute Error (lower is better)', fontsize=13, fontweight='bold')\nax.set_ylabel('MAE (EUR/MWh)')\nax.tick_params(axis='x', rotation=20)\n\n# (B) R2\nax2 = axes[1]\nbars2 = ax2.bar(model_names, r2s, color=bar_colors, alpha=0.8, edgecolor='white', lw=1.5)\nfor bar, val in zip(bars2, r2s):\n    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n             f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\nax2.set_title('(B) R-squared (higher is better)', fontsize=13, fontweight='bold')\nax2.set_ylabel('R$^2$')\nax2.tick_params(axis='x', rotation=20)\n\nfig.suptitle('Model Comparison: Romanian Electricity Price Forecasting',\n             fontsize=15, fontweight='bold', y=1.02)\nfig.tight_layout()\nsave_fig(fig, 'ml_model_comparison.pdf')\nplt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ]
}